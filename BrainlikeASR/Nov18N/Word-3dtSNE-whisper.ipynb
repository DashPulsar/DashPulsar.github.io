{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package cmudict to\n",
      "[nltk_data]     C:\\Users\\Alex\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package cmudict is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Alex\\anaconda3\\envs\\BayesPCN\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Alex\\anaconda3\\envs\\BayesPCN\\lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "890d411e9ba34f62844664a0e2d40e0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/185k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50346d9751b241568ff8543a47494506",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/283k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fe9a82835dcf411da5819843d77cbf06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/836k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "00be94fe25fd46ceb53aede29f431626",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/2.48M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b072e8954aa640c1a6bcac90b266fb4e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/494k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad682237a9c141568774b8e81377f6bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json:   0%|          | 0.00/52.7k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d391c04cf22c470fbf98e3e3baabae2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/34.6k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b446ee357dbf4fa2ac8c584d63c9be57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/2.19k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b02354dfe1b4a20b19fa694d44b3473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.97k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a2fe9f90bff49aca5c9ffb1c5e3aae7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/967M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ae5e7f99484fc4886ed3819b9f9bc5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/3.87k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from phonecodes import phonecodes\n",
    "from torchtext.data.utils import get_tokenizer\n",
    "from torchtext.vocab import build_vocab_from_iterator\n",
    "from typing import Iterable, List\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from timeit import default_timer as timer\n",
    "from torch.nn import Transformer\n",
    "from torch import Tensor\n",
    "from sklearn.model_selection import train_test_split\n",
    "import copy\n",
    "import tqdm\n",
    "import librosa\n",
    "import seaborn as sns\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import math\n",
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import textgrid\n",
    "from scipy.spatial.distance import euclidean\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "import jiwer\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "import nltk\n",
    "nltk.download('cmudict')\n",
    "from nltk.corpus import cmudict\n",
    "from transformers import AutoProcessor, AutoModelForCTC\n",
    "from phonemizer.backend.espeak.wrapper import EspeakWrapper\n",
    "import soundfile as sf\n",
    "\n",
    "_ESPEAK_LIBRARY = r\"C:\\Program Files\\eSpeak NG\\libespeak-ng.dll\"\n",
    "EspeakWrapper.set_library(_ESPEAK_LIBRARY)\n",
    "'''processor_P = AutoProcessor.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")\n",
    "model_P = AutoModelForCTC.from_pretrained(\"facebook/wav2vec2-lv-60-espeak-cv-ft\")'''\n",
    "\n",
    "\n",
    "from transformers import WhisperProcessor, WhisperForConditionalGeneration\n",
    "\n",
    "# 加载 Whisper 处理器\n",
    "processor_W = WhisperProcessor.from_pretrained(\"openai/whisper-small\")\n",
    "\n",
    "# 加载 Whisper 模型\n",
    "model_W = WhisperForConditionalGeneration.from_pretrained(\"openai/whisper-small\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pathset(paths):\n",
    "    return [os.path.join(dir, each_file) for dir, mid, files in os.walk(paths) for each_file in files if each_file.endswith(\".wav\")]\n",
    "audio_dir =r\"..\\Nov10\\speech_files\"\n",
    "set1_list=[0,1,2,3,4,5,6,7,8,9,10,12,13,14,15,16]\n",
    "set2_list=[17,18,19,20,21,22,24,25,26,27,28,29,30,31,37,40]\n",
    "    \n",
    "audio_path=get_pathset(audio_dir)\n",
    "audio, sr = librosa.load(audio_path[0])\n",
    "wave_res = librosa.resample(audio, orig_sr=sr, target_sr=16000)\n",
    "tg = textgrid.TextGrid.fromFile(audio_path[0][:-3]+\"TextGrid\")\n",
    "tg_sentence = tg[0]\n",
    "for _,i in enumerate(tg[0]):\n",
    "    if i.mark!=\"\":\n",
    "        tg_sentence[_-1].maxTime=tg_sentence[_].minTime\n",
    "tg_sentence = [i for i in tg_sentence if i.mark!=\"\"]\n",
    "tg_sentence=[tg_sentence[i] for i in set1_list+set2_list]\n",
    "tg_word = [i for i in tg[1] if i.mark!=\"\" and i.mark!=\"sp\"]\n",
    "model_W.to(device)\n",
    "for _,each_sentence in enumerate(tg_sentence):\n",
    "    each_sentence_list=[]\n",
    "    start_sentence = int(each_sentence.minTime*16000)\n",
    "    end_sentence = int(each_sentence.maxTime*16000)\n",
    "    input=processor_W(wave_res[start_sentence:end_sentence], sampling_rate=16000, return_tensors=\"pt\").input_features.to(device)\n",
    "    with torch.no_grad():\n",
    "        predicted_ids = model_W.generate(input)\n",
    "    \n",
    "        #out_encoder=model_W(input).logits\n",
    "        #out_FE=model.wav2vec2.feature_extractor(input)[0].transpose(1,0).cpu().numpy()\n",
    "    #outind=torch.argmax(out_encoder,dim=-1).cpu().numpy()\n",
    "    #out_encoder=copy.deepcopy(out_encoder).cpu().numpy()\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.6508, 2.9931, 5.6374,  ..., 3.1381, 3.2454, 3.7221]]],\n",
      "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)\n"
     ]
    }
   ],
   "source": [
    "decoder_input_ids = torch.tensor([[model_W.config.decoder_start_token_id]]).to(device)  # 起始 token\n",
    "outputs = model_W(input, decoder_input_ids=decoder_input_ids, output_hidden_states=True)\n",
    "print(outputs.logits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' A boy fell from the window.']\n"
     ]
    }
   ],
   "source": [
    "transcription = processor_W.batch_decode(predicted_ids, skip_special_tokens=True)\n",
    "print(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.6508, 2.9931, 5.6374,  ..., 3.1381, 3.2454, 3.7221]]],\n",
       "       device='cuda:0', grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.logits"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BayesPCN",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
